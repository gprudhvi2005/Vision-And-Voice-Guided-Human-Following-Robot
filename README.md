# -Vision-And-Voice-Guided-Human-Following-Robot
This project presents the design and development of an autonomous assistive robot capable of visually tracking a human and responding to voice commands in real time. Built with a modular architecture, the system integrates computer vision, control systems, and web technologies to enable both autonomous navigation and remote operation.

The robot uses YOLOv5 for human detection, combined with Kalman filtering and ADMM-based optimization for smooth tracking and trajectory refinement. A Kinematics manages motion dynamics, while an FFT-enhanced voice interface allows intuitive verbal commands like "follow me" or "stop."

To extend usability, a web-based interface provides live video streaming and remote control functionalities, allowing caregivers or users to monitor and guide the robot through a browser.

The solution is designed for real-world indoor applications requiring interactive human-following, assistive support, and remote oversight, showcasing a scalable model for intelligent home robotics.
